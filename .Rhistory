require(tidyverse)
require(igraph)
require(Matrix)
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
setwd("C:/Users/Simon/Dropbox/Scripts/R/SWOWGIT/SWOWEN-2018/R")
source('./R/functions/importDataFunctions.R')
setwd("C:/Users/Simon/Dropbox/Scripts/R/SWOWGIT/SWOWEN-2018/")
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
SWOWDir           = '../../complete/data/processed'
dataFile           = paste0(SWOWDir,'./data/processed/2012/SWOW-EN.R100.csv','')
outputFile.R123    = './output/2012/SWOW-NL.R123.networkstatsB.csv'
outputFile.R1      = './output/2012/SWOW-NL.R1.networkstatsB.csv'
compFile.R123      = './output/2012/SWOW-NL.R123.strongcomponent.removedvertices.csv'
X.R123 = importDataSWOW(dataFile,'R123')
SWOWDir           = '../../complete/data/processed'
dataFile           = paste0(SWOWDir,'./data/processed/2018/SWOW-EN.R100.csv','')
X.R123 = importDataSWOW(dataFile,'R123')
SWOWDir           = '../../complete/data/processed'
dataFile           = paste0(SWOWDir,'/2018/SWOW-EN.R100.csv','')
X.R123 = importDataSWOW(dataFile,'R123')
getwd()
SWOWDir           = '../complete/data/processed'
X.R123 = importDataSWOW(dataFile,'R123')
SWOWDir           = '../complete/data/processed'
dataFile           = paste0(SWOWDir,'/2018/SWOW-EN.R100.csv','')
X.R123 = importDataSWOW(dataFile,'R123')
G = list(); compResults = list(); results = list()
G$R123            = createGraph(X.R123)
outputFile.R123    = '../complete/output/2018/SWOW-EN.R123.networkstatsB.csv'
outputFile.R1      = '../complete/output/2018/SWOW-EN.R1.networkstatsB.csv'
compFile.R123      = '../complete/output/2018/SWOW-EN.R123.strongcomponent.removedvertices.csv'
write.csv(compResults$R123$removedVertices,compFile.R123)
outputFile.R123    = '../complete/output/2019/SWOW-EN.R123.networkstatsB.csv'
outputFile.R1      = '../complete/output/2019/SWOW-EN.R1.networkstatsB.csv'
compFile.R123      = '../complete/output/2019/SWOW-EN.R123.strongcomponent.removedvertices.csv'
write.csv(compResults$R123$removedVertices,compFile.R123)
results$R123$removeVertices = compResults$R123$removedVertices
results$R123$maxSize = compResults$R123$maxSize
G$R123.strong = normalizeEdgeWeights(G$R123.strong)
G
G$R123
G$R123.strong = normalizeEdgeWeights(G$R123.strong)
G$R123
G$R123.strong
G$R123.strong     = compResults$R123$subGraph
G$R123.strong     = compResults$R123$subGraph
G$R123.strong
compResults
compResults$R123  = extractComponent(G$R123,'strong')
compResults
compResults$R123$subGraph
G$R123.strong     = compResults$R123$subGraph
G$R123.strong
G$R123.strong = normalizeEdgeWeights(G$R123.strong)
networkstats       = list()
networkstats$k_in  = degree(G$R123.strong, v = V(G$R123.strong), mode = "in", loops = FALSE, normalized = FALSE)
networkstats$s_in  = strength(G$R123.strong, v = V(G$R123.strong), mode = "in", loops = FALSE)
G2 = list();
G2$R123.strong = G$R123.strong
E(G2$R123.strong)$weight = 1 - E(G2$R123.strong)$weight
networkstats$between = betweenness(G2$R123.strong,directed = TRUE,normalized = TRUE)
networkstats
networkstats$cue = names(networkstats$k_in)
networkstats = as.tibble(networkstats)
networkstats = networkstats %>% select(cue,k_in,s_in,between)
head(networkstats)
write.csv(networkstats,outputFile.R123)
X.R1 = importDataSWOW(dataFile,'R1')
G = list(); compResults = list()
G$R1            = createGraph(X.R1)
compResults$R1  = extractComponent(G$R1,'strong')
G$R1.strong     = compResults$R1$subGraph
results$R1$removeVertices = compResults$R1$removedVertices
results$R1$maxSize = compResults$R1$maxSize
G$R1.strong = normalizeEdgeWeights(G$R1.strong)
networkstats       = list()
networkstats$k_in  = degree(G$R1.strong, v = V(G$R1.strong), mode = "in", loops = FALSE, normalized = FALSE)
networkstats$s_in  = strength(G$R1.strong, v = V(G$R1.strong), mode = "in", loops = FALSE)
G2 = list();
G2$R1.strong = G$hR1.strong
E(G2$R1.strong)$weight = 1 - E(G2$R1.strong)$weight
G2 = list();
G2$R1.strong = G$hR1.strong
G2
G2$R1.strong = G$R1.strong
E(G2$R1.strong)$weight = 1 - E(G2$R1.strong)$weight
networkstats$between = betweenness(G2$R1.strong,directed = TRUE,normalized = TRUE)
networkstats$cue = names(networkstats$k_in)
networkstats = as.tibble(networkstats)
networkstats = networkstats %>% select(cue,k_in,s_in,between)
networkstats
write.csv(networkstats,outputFile.R1)
library('here')
source('./R/createWordlist.R')
source('./R/createWordlist.R')
source('./R/createWordlist.R')
source('./R/preprocessData.R')
source('./R/preprocessData.R')
source('./R/preprocessData.R')
source('./R/createResponseStats.R')
source('./R/createCueStats.R')
install.packages('pbapply')
source('./R/createCueStats.R')
install.packages('entropy')
source('./R/createCueStats.R')
source('./R/createSWOWGraph.R')
install.packages('igraph')
source('./R/createSWOWGraph.R')
source('./R/createCueStats.R')
source('./R/plotCoverage.R')
install.packages('cowplot')
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
dataFile          = '../data/2018/processed/SWOW-EN.R100.csv'
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = '../data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('../R/functions/importDataFunctions.R')
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = '../data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
getwd()
# Preprocessing pipeline for the English Small World of Words project (SWOWEN-2018)
# Author: Simon De Deyne (simon2d@gmail.com)
#
# Each file is self-contained, but the entire pipeline can be executed here
# Make sure the working directory is set to this file's directory
#
# Last changed: 13 July 2019
library('here')
# Compile an English word list to use for participant language checks
source('./R/createWordlist.R')
# Preprocess the data and generate participant statistics
source('./R/preprocessData.R')
getcwd()
getwd()
source('../R/preprocessData.R')
# Preprocess the data and generate participant statistics
source('./R/preprocessData.R')
source('./R/preprocessData.R')
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
X.R1              = importDataSWOW(dataFile,response)
# Import the dataset for R1
dataFile          = '../data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
X.R1              = importDataSWOW(dataFile,response)
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Extract unimodal graph (strong component)
G.R1              = createGraph(X.R1)
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Extract unimodal graph (strong component)
G.R1              = createGraph(X.R1)
compResults.R1    = extractComponent(G.R1,'strong')
G.R1.strong       = compResults.R1$subGraph
results$R1$removeVertices = compResults.R1$removedVertices
results$R1$maxSize = compResults.R1$maxSize
# Write adjacency and label files for G.raw
writeAdjacency(G.R1.strong, paste(output.file,response,sep=''))
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Extract unimodal graph (strong component)
G.R1              = createGraph(X.R1)
compResults.R1    = extractComponent(G.R1,'strong')
G.R1.strong       = compResults.R1$subGraph
results$R1$removeVertices = compResults.R1$removedVertices
results$R1$maxSize = compResults.R1$maxSize
# Write adjacency and label files for G.raw
writeAdjacency(G.R1.strong, paste(output.file,response,sep=''))
# Import the dataset for R123
response          = 'R123' # Options: R1, R2, R3 or R123
X.R123            = importDataSWOW(dataFile,response)
# Extract unimodal graph (strong component)
G.R123            = createGraph(X.R123)
compResults.R123  = extractComponent(G.R123,'strong')
G.R123.strong     = compResults.R123$subGraphx
results$R123$removeVertices = compResults.R123$removedVertices
results$R123$maxSize = compResults.R123$maxSize
# Write weighted adjacency file
writeAdjacency(G.R123.strong, paste(output.file,response,sep=''))
rlang::last_trace()
rlang::last_trace(drop = FALSE)
G.R123.strong     = compResults.R123$subGraphx
compResults.R123$subGraphx
compResults.R123  = extractComponent(G.R123,'strong')
View(compResults.R123)
# Description:
#
# Load English Small world of words data (https://smallworldofwords.org/)
# The input file consists of responses after spell checking and normalizing the tokens (Americanized)
# This script also removes cues that are British variants when an American one is available
#
# For each cue a total of 300 responses are available, consisting of 100 first, 100 second and 100 third responses
#
# The edge weights in the unimodal graph G.raw
# correspond to associative strength p(response|cue) after removing missing and unknown word responses
#
# Note: the data included with this script cannot be distributed without prior consent
# Author: Simon De Deyne simon2d@gmail.com
# Last changed: 13 June 2019
library('igraph')
library('Matrix')
results = list()
output.file         = './output/2018/adjacencyMatrices/SWOW-EN.'
report.file         = './output/2018/reports/components.SWOW-EN.rds'
source('settings.R')
source('./R/functions/importDataFunctions.R')
source('./R/functions/networkFunctions.R')
# Import the dataset for R1
dataFile          = './data/2018/processed/SWOW-EN.R100.csv'
response          = 'R1' # Options: R1, R2, R3 or R123
X.R1              = importDataSWOW(dataFile,response)
# Extract unimodal graph (strong component)
G.R1              = createGraph(X.R1)
compResults.R1    = extractComponent(G.R1,'strong')
G.R1.strong       = compResults.R1$subGraph
results$R1$removeVertices = compResults.R1$removedVertices
results$R1$maxSize = compResults.R1$maxSize
# Write adjacency and label files for G.raw
writeAdjacency(G.R1.strong, paste(output.file,response,sep=''))
# Import the dataset for R123
response          = 'R123' # Options: R1, R2, R3 or R123
X.R123            = importDataSWOW(dataFile,response)
# Extract unimodal graph (strong component)
G.R123            = createGraph(X.R123)
compResults.R123  = extractComponent(G.R123,'strong')
G.R123.strong     = compResults.R123$subGraph
results$R123$removeVertices = compResults.R123$removedVertices
results$R123$maxSize = compResults.R123$maxSize
# Write weighted adjacency file
writeAdjacency(G.R123.strong, paste(output.file,response,sep=''))
# Write a summary of the output to an rds file
saveRDS(results,report.file,ascii=TRUE)
# Clean up
rm(list = ls())
